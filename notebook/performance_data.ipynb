{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/Challenge_Data/performance_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>preview_link</th>\n",
       "      <th>ER</th>\n",
       "      <th>CTR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bfbf7a2b7ac635e67877b1ab87fd6629</td>\n",
       "      <td>https://s3.us-east-1.amazonaws.com/a.futureadl...</td>\n",
       "      <td>0.209269</td>\n",
       "      <td>0.058438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>945010afbf9a55bbdffcb0895f946155</td>\n",
       "      <td>https://s3.us-east-1.amazonaws.com/a.futureadl...</td>\n",
       "      <td>0.274552</td>\n",
       "      <td>0.074731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e68e20f592457b875ce29757ab855dfe</td>\n",
       "      <td>https://s3.us-east-1.amazonaws.com/a.futureadl...</td>\n",
       "      <td>0.103688</td>\n",
       "      <td>0.042228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adunit-nestle-purina-friskies-mob</td>\n",
       "      <td>https://s3.ap-southeast-1.amazonaws.com/a.futu...</td>\n",
       "      <td>0.136963</td>\n",
       "      <td>0.005393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adunit-lionsgate-uwomt-user-slider-sensory-vid...</td>\n",
       "      <td>https://s3.us-west-1.amazonaws.com/a.futureadl...</td>\n",
       "      <td>0.114208</td>\n",
       "      <td>0.016443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             game_id  \\\n",
       "0                   bfbf7a2b7ac635e67877b1ab87fd6629   \n",
       "1                   945010afbf9a55bbdffcb0895f946155   \n",
       "2                   e68e20f592457b875ce29757ab855dfe   \n",
       "3                  adunit-nestle-purina-friskies-mob   \n",
       "4  adunit-lionsgate-uwomt-user-slider-sensory-vid...   \n",
       "\n",
       "                                        preview_link        ER       CTR  \n",
       "0  https://s3.us-east-1.amazonaws.com/a.futureadl...  0.209269  0.058438  \n",
       "1  https://s3.us-east-1.amazonaws.com/a.futureadl...  0.274552  0.074731  \n",
       "2  https://s3.us-east-1.amazonaws.com/a.futureadl...  0.103688  0.042228  \n",
       "3  https://s3.ap-southeast-1.amazonaws.com/a.futu...  0.136963  0.005393  \n",
       "4  https://s3.us-west-1.amazonaws.com/a.futureadl...  0.114208  0.016443  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Engagement Rate (ER) - the number of engagements divided by the number of impressions\n",
    "\n",
    "Click Through Rate (CTR) - the number of clicks divided by the number of engagements\n",
    "\n",
    "Video Through Rate (VTR) - the number of videos ends divided by the number of engagements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://s3.us-east-1.amazonaws.com/a.futureadlabs.com-us-east-1-backup/us-east-1/games/bfbf7a2b7ac635e67877b1ab87fd6629/b7a604b3b08f0862ef0e/index.html'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0].preview_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locate_image_on_image(locate_image: str, on_image: str, prefix: str = '', visualize: bool = False, color: Tuple[int, int, int] = (0, 0, 255)):\n",
    "    try:\n",
    "\n",
    "        image = cv2.imread(on_image)\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        template = cv2.imread(locate_image, 0)\n",
    "\n",
    "        result = cv2.matchTemplate(gray, template, cv2.TM_CCOEFF)\n",
    "        _, _, _, max_loc = cv2.minMaxLoc(result)\n",
    "\n",
    "        height, width = template.shape[:2]\n",
    "\n",
    "        top_left = max_loc\n",
    "        bottom_right = (top_left[0] + width, top_left[1] + height)\n",
    "\n",
    "        if visualize:\n",
    "            cv2.rectangle(image, top_left, bottom_right, color, 1)\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            plt.axis('off')\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            plt.imshow(image)\n",
    "\n",
    "        return {f'{prefix}top_left_pos': top_left, f'{prefix}bottom_right_pos': bottom_right}\n",
    "\n",
    "    except cv2.error as err:\n",
    "        print(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV(4.9.0) /Users/xperience/GHA-OpenCV-Python2/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@299.096] global loadsave.cpp:248 findDecoder imread_('..Data/Assets/5a48ffcbf611f167ecbb884e807f31f6/_preview.png'): can't open/read file: check file path/integrity\n"
     ]
    }
   ],
   "source": [
    "locate_image_on_image(\n",
    "    '..Data/Assets/5a48ffcbf611f167ecbb884e807f31f6/engagement_instruction.png', '..Data/Assets/5a48ffcbf611f167ecbb884e807f31f6/_preview.png', prefix='eng_', visualize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "from typing import List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_hex_to_rgb(hex_color: str, normalize: bool = True) -> List[str]:\n",
    "    \"\"\"Converts a HEX color to a RGB color\n",
    "\n",
    "    Args:\n",
    "        hex_color (str): HEX color code to convert\n",
    "        normalize (bool, optional): Choice to normalize calculated rgb values . Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of RGB values in order, normalized or not.\n",
    "    \"\"\"\n",
    "    colors = hex_color[1:]\n",
    "\n",
    "    # Convert HEX color values to RGB Values\n",
    "    colors = [int(colors[0:2], base=16),  # RED\n",
    "              int(colors[2:4], base=16),  # GREEN\n",
    "              int(colors[4:6], base=16)]  # BLUE\n",
    "\n",
    "    # Normalize RGB values\n",
    "    if normalize:\n",
    "        colors = [color / 255 for color in colors]\n",
    "\n",
    "    return colors\n",
    "\n",
    "def get_luminance(hex_color: str) -> float:\n",
    "    \"\"\"Calculates the luminance of a given HEX color\n",
    "\n",
    "    Args:\n",
    "        hex_color (str): HEX color code to calculate luminance for\n",
    "\n",
    "    Returns:\n",
    "        float: luminance value of color\n",
    "    \"\"\"\n",
    "    colors = convert_hex_to_rgb(hex_color)\n",
    "\n",
    "    luminance = colors[0] * 0.2126 + colors[1] * 0.7152 + colors[2] * 0.0722\n",
    "\n",
    "    return luminance\n",
    "\n",
    "def fix_image_background(image_path: str):\n",
    "    identified_colors = identify_color_composition(image_path)\n",
    "    text_color = identified_colors['c_code'].to_list()[0]\n",
    "    text_color_rgb = identified_colors['rgb'].to_list()[0]\n",
    "    luminance = get_luminance(hex_color=text_color)\n",
    "\n",
    "    if luminance < 140:\n",
    "        background_color = (255, 255, 255)\n",
    "    else:\n",
    "        background_color = (0, 0, 0)\n",
    "\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Make all perfectly green pixels white\n",
    "    image[np.all(image != text_color_rgb, axis=-1)] = background_color\n",
    "\n",
    "    return image\n",
    "\n",
    "def extract_text(image_path, tesseract_cmd: str = '', fix_background: bool = False):\n",
    "    # pytesseract.pytesseract.tesseract_cmd = tesseract_cmd\n",
    "    try:\n",
    "        if fix_background:\n",
    "            text = pytesseract.image_to_string(\n",
    "                fix_image_background(image_path))\n",
    "        else:\n",
    "            text = pytesseract.image_to_string(image_path)\n",
    "\n",
    "        return text\n",
    "\n",
    "    except pytesseract.TesseractNotFoundError:\n",
    "        raise Exception(\n",
    "            f'Failure: Tesseract is not installed or not available in the defined path {tesseract_cmd}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from os import path\n",
    "from subprocess import Popen, call\n",
    "import pyautogui\n",
    "import ffmpeg # library used for audio & videw processing and gerneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreativeFrameExtractor:\n",
    "    '''\n",
    "    Class responsible for Extracting Creative Start and End Frames.\n",
    "    It requires a chrome webdriver compatible with selenium to be\n",
    "    installed/included in the run environment path.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, preview_url: str,\n",
    "                 engagement_type: str,\n",
    "                 save_location: str = '',\n",
    "                 browser_edges: Tuple[float, float] = (70, 1039)) -> None: # crop the image\n",
    "\n",
    "        self.preview_url = preview_url\n",
    "        self.engagement_type = engagement_type\n",
    "        self.browser_edges = browser_edges\n",
    "        self.file_name = '-'.join(preview_url.split('/')[-3:-1]) # extracting the file name from url\n",
    "        self.save_location = save_location\n",
    "        self.video_name = path.join(self.save_location, self.file_name) # video name\n",
    "        self.cmd = f\"ffmpeg -f gdigrab -draw_mouse 0 -framerate 60 -i desktop -vcodec libx264rgb {self.video_name}.mkv -y\"\n",
    "\n",
    "        # Configurations # of the selenium\n",
    "\n",
    "        # Browser Configuration\n",
    "        # Browser Options\n",
    "        self.opt = Options()\n",
    "        self.opt.add_argument(\"--hide-scrollbars\")\n",
    "        self.opt.add_experimental_option(\n",
    "            \"excludeSwitches\", [\"enable-automation\"])\n",
    "        # Browser Logs # If you want to extract browser logs\n",
    "        self.capabilities = DesiredCapabilities.CHROME\n",
    "        self.capabilities[\"goog:loggingPrefs\"] = {\"browser\": \"ALL\"}\n",
    "\n",
    "    def is_status_complete(self, passed_driver) -> bool:\n",
    "        '''\n",
    "        Function to check status of the AD-Unit and its completion. #different phases of AD\n",
    "        # we use this to track when to get the end/start frame, start/end of recording\n",
    "        '''\n",
    "        # Retrieve logs from browser\n",
    "        logs = passed_driver.get_log(\"browser\")\n",
    "\n",
    "        for log in logs:\n",
    "            # Select logs coming from AD-Unit\n",
    "            if log[\"source\"] == \"console-api\":\n",
    "                # Extract message from log\n",
    "                message = log[\"message\"]\n",
    "\n",
    "                if '\"GAME CREATED\"' in message or '\"DROPPED\"' in message:\n",
    "                    # Start Recording Game\n",
    "                    print(\"Starting Recording AD-UNIT...\")\n",
    "                    print(log)\n",
    "                    return False\n",
    "\n",
    "                if '\"START\"' in message:\n",
    "                    # Engaged\n",
    "                    print(\"AD-UNIT Engaged...\")\n",
    "                    print(log)\n",
    "                    return False\n",
    "\n",
    "                if '\"GAME COMPLETE\"' in message:\n",
    "                    # Stop Recording Game\n",
    "                    print(\"Stopped Recording AD-UNIT...\")\n",
    "                    print(log)\n",
    "                    return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    @staticmethod\n",
    "    def terminate(process: Popen[bytes]) -> None:\n",
    "        '''\n",
    "        Function to stop/terminate a process.\n",
    "        '''\n",
    "        # Video Recording Process Terminator\n",
    "        if process.poll() is None:\n",
    "            call(\"taskkill /F /T /PID \" + str(process.pid))\n",
    "\n",
    "    @staticmethod\n",
    "    def crop_video(filename: str, x_pos: float = 0, y_pos: float = 70, width: float = 650, height: float = 970) -> None:\n",
    "        '''\n",
    "        Function to crop a video with given location and size specific parameters. # we need this because the record function records entire screen\n",
    "        '''\n",
    "        print(filename)\n",
    "        input_video = ffmpeg.input(f\"{filename}.mkv\")\n",
    "        cropped_video = ffmpeg.crop(input_video, x_pos, y_pos, width, height)\n",
    "        output_video = ffmpeg.output(cropped_video, f\"{filename}_cropped.mkv\")\n",
    "        ffmpeg.run(output_video)\n",
    "\n",
    "    def _imitate_engagement(self, ad_size: Tuple[float, float]) -> None:\n",
    "        '''\n",
    "        Function to imitate a given engagement type. # are these comprehensive?\n",
    "        '''\n",
    "        center = (ad_size[0]/2, self.browser_edges[0] + (ad_size[1]/2))\n",
    "\n",
    "        if self.engagement_type == \"tap\":\n",
    "            pyautogui.moveTo(center[0], center[1], duration=1)\n",
    "            pyautogui.leftClick()\n",
    "\n",
    "        elif self.engagement_type == \"swipe right\":\n",
    "            pyautogui.moveTo(center[0], center[1], duration=1)\n",
    "            pyautogui.dragRel(center[0], 0, duration=1)\n",
    "\n",
    "        elif self.engagement_type == \"swipe left\":\n",
    "            pyautogui.moveTo(center[0], center[1], duration=1)\n",
    "            pyautogui.dragRel(-center[0], 0, duration=1)\n",
    "\n",
    "        elif self.engagement_type == \"tap and hold\":\n",
    "            pyautogui.moveTo(center[0], center[1], duration=1)\n",
    "            pyautogui.click()\n",
    "\n",
    "        elif self.engagement_type == \"scrub\":\n",
    "            pyautogui.moveTo(center[0] - (1/2 * center[0]),\n",
    "                             center[1] - (2/3 * center[1]), duration=0.2)\n",
    "            pyautogui.dragRel(center[0], 0, duration=0.2)\n",
    "            pyautogui.dragRel(-center[0], (1/3 * center[1]), duration=0.2)\n",
    "            pyautogui.dragRel(center[0], 0, duration=0.2)\n",
    "            pyautogui.dragRel(-center[0], (1/3 * center[1]), duration=0.2)\n",
    "            pyautogui.dragRel(center[0], 0, duration=0.2)\n",
    "\n",
    "    def generate_preview_video(self) -> None:\n",
    "        '''\n",
    "        Function to generate preview video and also a cropped version of the video.\n",
    "        '''\n",
    "        # Initialize Selenium WebDriver\n",
    "        driver = webdriver.Chrome(\n",
    "            options=self.opt, desired_capabilities=self.capabilities)\n",
    "        # Maximize WebDriver's Window to Maximum Size\n",
    "        driver.maximize_window()\n",
    "\n",
    "        try:\n",
    "            # Load AD-Unit through Selenium\n",
    "            driver.get(self.preview_url)\n",
    "\n",
    "            # Locate AD-Unit Element from Browser\n",
    "            canvas = driver.find_element(By.TAG_NAME, \"canvas\")\n",
    "\n",
    "            # Start Recording Entire Screen\n",
    "            video_recording = Popen(self.cmd)\n",
    "\n",
    "            # Identify Size of AD-Unit\n",
    "            ad_size = (canvas.size.get(\"width\"), canvas.size.get(\"height\"))\n",
    "\n",
    "            # Engage Ad-Unit\n",
    "            self._imitate_engagement(ad_size)\n",
    "\n",
    "            # Continuously Check Status of AD-Unit using its console logs\n",
    "            # until it reached a \"GAME COMPLETE\" Status\n",
    "            WebDriverWait(driver, 100).until(self.is_status_complete)\n",
    "\n",
    "            sleep(5)\n",
    "\n",
    "            # Stop Video Recording\n",
    "            self.terminate(video_recording)\n",
    "\n",
    "            # Close Selenium Browser Window\n",
    "            driver.close()\n",
    "\n",
    "            # Crop Generated Preview Video Recording\n",
    "            self.crop_video(self.video_name, x_pos=0, y_pos=70,\n",
    "                            width=ad_size[0], height=ad_size[1])\n",
    "\n",
    "        except TimeoutException:\n",
    "            print(\"TimeOut Exception Fired\")\n",
    "            print(\"AD-Unit Status Console Logs did not Complete. Engagement Failed.\")\n",
    "            driver.close()\n",
    "\n",
    "        except NoSuchElementException:\n",
    "            print(f\"AD-Unit Failed to Load: {self.preview_url}\")\n",
    "            driver.close()\n",
    "\n",
    "    def generate_frames(self) -> None:\n",
    "        '''\n",
    "        Function to generate creative start and end frames.\n",
    "        '''\n",
    "        # Initialize Selenium WebDriver\n",
    "        driver = webdriver.Chrome(\n",
    "            options=self.opt, desired_capabilities=self.capabilities, )\n",
    "        # Maximize WebDriver's Window to Maximum Size\n",
    "        driver.maximize_window()\n",
    "\n",
    "        try:\n",
    "            # Load AD-Unit through Selenium\n",
    "            driver.get(self.preview_url)\n",
    "\n",
    "            # Locate AD-Unit Element from Browser\n",
    "            canvas = driver.find_element(By.TAG_NAME, \"canvas\")\n",
    "\n",
    "            # Capture Start Frame\n",
    "            canvas.screenshot(\n",
    "                path.join(self.save_location, f'{self.file_name}_start_frame.png'))\n",
    "            print('Start Frame captured')\n",
    "\n",
    "            # Identify Size of AD-Unit\n",
    "            ad_size = (canvas.size.get(\"width\"), canvas.size.get(\"height\"))\n",
    "\n",
    "            # Engage Ad-Unit\n",
    "            self._imitate_engagement(ad_size)\n",
    "\n",
    "            # Continuously Check Status of AD-Unit using its console logs\n",
    "            # until it reached a \"GAME COMPLETE\" Status\n",
    "            WebDriverWait(driver, 100).until(self.is_status_complete)\n",
    "\n",
    "            sleep(5)\n",
    "\n",
    "            # Capture End Frame\n",
    "            canvas.screenshot(path.join(self.save_location,f'{self.file_name}_end_frame.png'))\n",
    "            print('End Frame Captured')\n",
    "\n",
    "            # Close Selenium Browser Window\n",
    "            driver.close()\n",
    "\n",
    "        except TimeoutException:\n",
    "            print(\"TimeOut Exception Fired\")\n",
    "            print(\"AD-Unit Status Console Logs did not Complete. Engagement Failed.\")\n",
    "            driver.close()\n",
    "\n",
    "        except NoSuchElementException:\n",
    "            print(f\"AD-Unit Failed to Load: {self.preview_url}\")\n",
    "            driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
